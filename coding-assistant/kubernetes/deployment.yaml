apiVersion: apps/v1
kind: Deployment
metadata:
  name: coding-assistant
  namespace: gpu-assistant
spec:
  replicas: 1
  revisionHistoryLimit: 3

  strategy:
    type: RollingUpdate
    rollingUpdate:
    # kill one old pod first (so you never end up waiting on a stuck replica)
    maxUnavailable: 1
    # donâ€™t create an extra surge pod
    maxSurge:       0

  selector:
    matchLabels:
      app: mathsgpt-gpu
  template:
    metadata:
      labels:
        app: mathsgpt-gpu
    spec:
      serviceAccountName: mathsgpt-deployer
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      nodeSelector:
        cloud.google.com/gke-nodepool: "mathsgpt-gpu-cluster-gpu-pool"
      containers:
        - name: coding-assistant
          image: docker.io/ankitb47/maths-gpt:gpu_v1
          imagePullPolicy: Always
          ports:
            - containerPort: 8501
          resources:
            requests:
              cpu:      "2"
              memory:   "4Gi"
              nvidia.com/gpu: 1
            limits:
              cpu:      "4"
              memory:   "8Gi"
              nvidia.com/gpu: 1
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key:  HF_TOKEN
